{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning for medical claims -- Autoencoders for billing codes\n",
    "\n",
    "I've recently been exploring ways to extract more information from the billing claims data that I tend to work with. \n",
    "\n",
    "Anthem covers 40.2 million lives, so you can imagine that the size/scope of our claims data is in the billions of records. Each claim contains a bit of information about a member -- what services were delivered and where, what diseases/symptoms prompted the service, what was the cost of the service, who delivered the service, etc..Trying to extract insights from these bits and pieces can be a challenge that typically requires a great deal of human input. Data scientists would call it heavy feature engineering. \n",
    "\n",
    "Sure, some information is encoded because coding systems are designed to enforce meanings (e.g., ICD, CPT-4, and Medispan GPI codes have a hierarchical structure where higher digits aggregate diseases/procedures/drugs into  larger clinically similar groups). Still, in practice we've noticed a few issues with codes *as-is*:\n",
    "\n",
    "1. There are few, if any, systems that permit understanding of relationships across coding systems. That is, absent clinical expertise, it is a challenge to know whether and how a 3-digit ICD-9 code like 520 'Disorder of tooth development and eruption' relates to an NDC code like 64116001101, which codes for a type of Interferon-Gamma.\n",
    "2. When semantic relations among codes are captured, it is usually on an ad-hoc basis and requires input from clinical experts. Relationships have to be continuously monitored and updated (especially relations using NDC or Medispan GPI relationships) depending on new technologies/drugs/etc...\n",
    "3. Coding schemes are discrete and high-dimensional; for ex., there are over 70,000 ICD-10 CM codes. This means that in predictive modeling or other tasks some form of dimensionality reduction has to be used, whether it be the exlcusion of certain codes because they aren't relevant or \n",
    "\n",
    "In struggling with these problems we've started playing with the use of deep learning techniques to extract structure from our data. In particular, we've been exploring the use of [autoencoders](https://en.wikipedia.org/wiki/Autoencoder) to extract meaning among this large, disordered set of codes. \n",
    "\n",
    "## An overly simple intro to autoencoders\n",
    "\n",
    "Autoencoders are a type of deep learning or a type of neural network architecture. Their general goal is to take a set of inputs and then predict those same inputs using a lower-dimensional representation of the data. In other words, these tools learn more parsimonius ways of representing potentially high-dimensional data. Below is a nice picture, courtesy of Stanford's deep learning group, that I actually found on [another site](https://www.doc.ic.ac.uk/~js4416/163/website/nlp/) providing a good description of autoencoders in the context of natural lnaguage processing.\n",
    "\n",
    "![Image of autoencoder](http://ufldl.stanford.edu/tutorial/images/Autoencoder636.png) \n",
    "\n",
    "In the image you see an input of 6 cells (X) + 1 bias term cell. These feed to an intermediate layer of 4 cells (3 with inputs, 1 bias) and an output layer of, again, 6 cells. In those 4 cells we enage in 'encoding' information, condensing it down into a smaller dimension. We then engage in decoding this information back out.\n",
    "\n",
    "There's actually a lot of depth and variation to this basic idea. For example, we can add a little bit of noise or drop some input connections out to make it more difficult for the model to learn, or we can add multiple intermediate layers (stacked autoencoders), or... Still, though, the basic idea remains the same: learn how to predict or re-create data using a lower-dimensional representation of it. At least, that's my high-level understanding.\n",
    "\n",
    "In the code below I'll show how to apply the concept of autoencoders to ICD-9 CM codes using TensorFlow.\n",
    "\n",
    "## Step 1: Calling in and getting the data ready\n",
    "\n",
    "Our data will come from the Medical Expenditures Panel Survey (MEPS), specifically the 'medical component' from the 2015 and 2016 years. I've actually done a little pre-processing in R prior to this step. First, I used the R `lodown` package to download the data. Second, I did a little data tidying with `dplyr`. The result is a data set where eah individual is a single row, and each column corresponds to an ICD-9 code. A value of `1` indicates the individual has the medical condition, a value of `0` means they do not (i.e., a 'one-hot' encoding of the data). You can see the data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dupersid  005  008  009  034  041  053  054  070  074 ...   V68  V70  V71  \\\n",
      "0  40001101    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "1  40001102    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "2  40001104    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "3  40002101    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "4  40004102    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "5  40004103    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "6  40004104    0    0    0    0    0    0    0    0    0 ...     0    1    0   \n",
      "7  40004105    0    0    0    0    0    0    0    0    0 ...     0    1    0   \n",
      "8  40004106    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
      "9  40004107    0    0    0    0    0    0    0    0    0 ...     1    1    0   \n",
      "\n",
      "   V72  V74  V76  V77  V80  V81  V82  \n",
      "0    0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0    0  \n",
      "4    0    0    1    0    0    0    0  \n",
      "5    0    0    0    0    0    0    0  \n",
      "6    1    0    0    0    0    0    0  \n",
      "7    1    0    0    0    0    0    0  \n",
      "8    0    0    0    0    0    0    0  \n",
      "9    0    0    0    0    0    0    0  \n",
      "\n",
      "[10 rows x 367 columns]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "d_in = pd.read_csv(\"~/Desktop/Mike-McLaughlin.github.io/_drafts/meps_onehot.csv\")\n",
    "\n",
    "print(d_in.head(n = 10))\n",
    "\n",
    "#Drop the id column, add a bias column\n",
    "d_in2 = d_in.drop(['dupersid'], axis=1)\n",
    "n, p = d_in2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   005  008  009  034  041  053  054  070  074  075 ...   V68  V70  V71  V72  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
      "\n",
      "   V74  V76  V77  V80  V81  V82  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    1    0    0    0    0  \n",
      "\n",
      "[5 rows x 366 columns]\n"
     ]
    }
   ],
   "source": [
    "#Need to extract \n",
    "print(d_in2[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the autoencoder in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "#Drop 1 column because we don't want to include the ID var\n",
    "n_inputs = p\n",
    "n_hidden_1 = 25 #25 cells--> Reduce from ~350 to 25\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs])\n",
    "hidden = fully_connected(X, n_hidden)\n",
    "logits = fully_connected(hidden, n_outputs)\n",
    "outputs = tf.sigmoid(logits)\n",
    "reconstruction_loss = tf.reduce_sum(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(labels = X, logits = logits))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = tf.optimizer.minimize(reconstruction_loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_iterations = 100\n",
    "codings = hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>005</th>\n",
       "      <th>008</th>\n",
       "      <th>009</th>\n",
       "      <th>034</th>\n",
       "      <th>041</th>\n",
       "      <th>053</th>\n",
       "      <th>054</th>\n",
       "      <th>070</th>\n",
       "      <th>074</th>\n",
       "      <th>075</th>\n",
       "      <th>...</th>\n",
       "      <th>V68</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V74</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   005  008  009  034  041  053  054  070  074  075 ...   V68  V70  V71  V72  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   V74  V76  V77  V80  V81  V82  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    1    0    0    0    0  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8edd3d056e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        training_op.run(feed_dict={X : })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
